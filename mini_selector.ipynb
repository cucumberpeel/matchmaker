{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bdikit as bdi\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>title_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>title_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Barts Health NHS Trust</td>\n",
       "      <td>0</td>\n",
       "      <td>Barts and The London NHS Trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Klinikum Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Uniklinikum Aachen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Moorfields Eye Hospital NHS Foundation Trust</td>\n",
       "      <td>2</td>\n",
       "      <td>Moorfields Eye Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>Hospital for Sick Children</td>\n",
       "      <td>3</td>\n",
       "      <td>The Hospital for Sick Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>Princess Margaret Cancer Centre</td>\n",
       "      <td>4</td>\n",
       "      <td>Princess Margaret Hospital (Toronto)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_l                                       title_l  id_r  \\\n",
       "0     5                        Barts Health NHS Trust     0   \n",
       "1     8                               Klinikum Aachen     1   \n",
       "2    16  Moorfields Eye Hospital NHS Foundation Trust     2   \n",
       "3    31                    Hospital for Sick Children     3   \n",
       "4    47               Princess Margaret Cancer Centre     4   \n",
       "\n",
       "                                title_r  \n",
       "0        Barts and The London NHS Trust  \n",
       "1                    Uniklinikum Aachen  \n",
       "2               Moorfields Eye Hospital  \n",
       "3        The Hospital for Sick Children  \n",
       "4  Princess Margaret Hospital (Toronto)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = pd.read_csv('data/Hospital/gt.csv')\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = raw_dataset['title_r'].unique().tolist()\n",
    "\n",
    "# Create list of dicts\n",
    "dataset = []\n",
    "for _, row in raw_dataset.iterrows():\n",
    "    dataset.append({\n",
    "        'source': row['title_l'],\n",
    "        'gold': row['title_r'],\n",
    "        'targets': all_targets,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Barts Health NHS Trust',\n",
       " 'gold': 'Barts and The London NHS Trust',\n",
       " 'targets': ['Barts and The London NHS Trust',\n",
       "  'Uniklinikum Aachen',\n",
       "  'Moorfields Eye Hospital',\n",
       "  'The Hospital for Sick Children',\n",
       "  'Princess Margaret Hospital (Toronto)',\n",
       "  'Queen Mary Hospital (Hong Kong)',\n",
       "  'Mount Sinai Hospital (Manhattan)',\n",
       "  \"Evelina London Children's Hospital\",\n",
       "  'James Paget University Hospitals NHS Foundation Trust',\n",
       "  'LAC+USC Medical Center',\n",
       "  'TYKS',\n",
       "  'NYC Health + Hospitals/Bellevue',\n",
       "  'Royal Stoke University Hospital',\n",
       "  'Oslo University Hospital, Rikshospitalet',\n",
       "  'WellStar Kennestone Regional Medical Center',\n",
       "  \"Children's Medical Center Dallas\",\n",
       "  'St John of God Hospital Geelong',\n",
       "  'Prince of Wales Hospital (Sydney)',\n",
       "  \"St Vincent's Private Hospital\",\n",
       "  'Aalborg University Hospital',\n",
       "  'Wagga Wagga Rural Referral Hospital',\n",
       "  'Florida Hospital',\n",
       "  'University of California, Irvine Medical Center',\n",
       "  'UC San Diego Health',\n",
       "  'Lankenau Hospital',\n",
       "  'Queen Elizabeth Hospital (Hong Kong)',\n",
       "  'Countess of Chester Hospital',\n",
       "  'Princess Margaret Hospital (Hong Kong)',\n",
       "  'Kingston Hospital NHS Foundation Trust',\n",
       "  \"Queen Elizabeth Hospital King's Lynn NHS Foundation Trust\",\n",
       "  'Newham General Hospital',\n",
       "  \"Liverpool Women's NHS Foundation Trust\",\n",
       "  'York Central Hospital',\n",
       "  'AtlantiCare',\n",
       "  'CentraState Healthcare System',\n",
       "  'Salford Royal NHS Foundation Trust',\n",
       "  'Bayfront Health St. Petersburg',\n",
       "  'Wesley Long Hospital',\n",
       "  'King Faisal Specialist Hospital',\n",
       "  'University of Maryland St. Joseph Medical Center',\n",
       "  'St. Joseph Medical Center (Towson, Maryland)',\n",
       "  'The University of Vermont Medical Center',\n",
       "  'Lower Manhattan Hospital',\n",
       "  'The James Cancer Hospital',\n",
       "  'State Hospital for Scotland and Northern Ireland',\n",
       "  \"Birmingham Children's Hospital NHS Foundation Trust\",\n",
       "  'Queen Elizabeth Hospital, London',\n",
       "  'Government General Hospital',\n",
       "  'University Hospital Southampton NHS Foundation Trust',\n",
       "  'Houston Methodist Hospital',\n",
       "  'Bedford Hospital NHS Trust',\n",
       "  \"St Margaret's Hospital, Sydney\",\n",
       "  \"St Margaret's Hospital\",\n",
       "  \"Alder Hey Children's NHS Foundation Trust\",\n",
       "  'County Hospital, Torfaen',\n",
       "  'Ben Taub Hospital',\n",
       "  'Carolinas Medical Center',\n",
       "  'Carolinas HealthCare System University',\n",
       "  'Hong Kong Sanatorium & Hospital',\n",
       "  'Carolinas HealthCare System Union',\n",
       "  'Indiana University Health Methodist Hospital',\n",
       "  'Croydon Health Services NHS Trust',\n",
       "  'Monmouth Medical Center Southern Campus',\n",
       "  'Mayo University Hospital',\n",
       "  'Aravind Eye Hospitals',\n",
       "  'IU Health University Hospital',\n",
       "  'Ealing Hospital',\n",
       "  'Montreal Neurological Institute and Hospital',\n",
       "  'Kiang Wu Hospital',\n",
       "  'NYC Health + Hospitals/Kings County',\n",
       "  'NYC Health + Hospitals/Coney Island',\n",
       "  'Milton Keynes University Hospital',\n",
       "  'Milton Keynes Hospital',\n",
       "  'Adventist HealthCare Shady Grove Medical Center',\n",
       "  'University Hospital Galway',\n",
       "  'Letterkenny University Hospital',\n",
       "  'Royal Victoria Regional Health Centre',\n",
       "  'Howard University Hospital',\n",
       "  \"Freedman's Hospital\",\n",
       "  'Union Memorial Hospital',\n",
       "  \"British Columbia Children's Hospital\",\n",
       "  'Ipswich Hospital NHS Trust',\n",
       "  'Lahey Hospital & Medical Center',\n",
       "  'Robert Wood Johnson University Hospital Somerset',\n",
       "  'University Medical Center at Princeton',\n",
       "  'Dartford and Gravesham NHS Trust',\n",
       "  'Advocate Sherman Hospital',\n",
       "  'Dorset County Hospital NHS Foundation Trust',\n",
       "  'Pali Momi Medical Center',\n",
       "  'Hotel Dieu Hospital (Kingston)',\n",
       "  'Korle-Bu Teaching Hospital',\n",
       "  'Southern New Hampshire Health System',\n",
       "  'Sabbatsberg Hospital',\n",
       "  'Gloucestershire Hospitals NHS Foundation Trust',\n",
       "  'Sidney and Lois Eskenazi Hospital',\n",
       "  'Marina Del Rey Hospital',\n",
       "  \"Saint Mary's Regional Medical Center (Reno)\",\n",
       "  'Franklin Square Hospital Center',\n",
       "  \"Primary Children's Hospital\",\n",
       "  'Paradise Valley Hospital California',\n",
       "  'Jordan Valley Medical Center West Valley Campus',\n",
       "  'Western State Hospital (Washington)',\n",
       "  'Butterworth Hospital',\n",
       "  'MedStar Georgetown University Hospital',\n",
       "  'University Hospitals Portage Medical Center',\n",
       "  'MedStar Washington Hospital Center',\n",
       "  'University of Maryland Baltimore Washington Medical Center',\n",
       "  'UF Health Jacksonville',\n",
       "  'UF Health at Jacksonville',\n",
       "  'Carolinas HealthCare System NorthEast',\n",
       "  \"Seamen's Hospital\",\n",
       "  'University Hospital Ayr',\n",
       "  'Nalanda Medical College & Hospital',\n",
       "  'Shatin Hospital',\n",
       "  'Centegra Hospital - McHenry',\n",
       "  'Centegra Hospital - Woodstock',\n",
       "  'CaroMont Regional Medical Center',\n",
       "  \"St. Olav's University Hospital\",\n",
       "  'Beaumont Health',\n",
       "  'William Beaumont Hospital',\n",
       "  'Michael Garron Hospital',\n",
       "  'Medical Center of Central Georgia, Navicent Health',\n",
       "  'Imperial College Healthcare NHS Trust',\n",
       "  \"Baylor St. Luke's Medical Center\",\n",
       "  'Evangel Hospital',\n",
       "  \"St. Teresa's Hospital (Hong Kong)\",\n",
       "  'Canossa Hospital (Caritas)',\n",
       "  'Lincoln Hospital (Bronx)',\n",
       "  'University Hospital of South Manchester NHS Foundation Trust',\n",
       "  'McKay-Dee Hospital',\n",
       "  'Queen Elizabeth Hospital (Charlottetown)',\n",
       "  'Joseph Brant Hospital',\n",
       "  \"Nationwide Children's Hospital\",\n",
       "  'University of Maryland Medical Center Midtown Campus',\n",
       "  'Parkview Health',\n",
       "  \"St. Mary's General Hospital (Passaic, New Jersey)\",\n",
       "  'Fairfield Hospital, Stotfold',\n",
       "  'Inspira Health Network',\n",
       "  'Lexington VA Medical Center',\n",
       "  \"Coombe Women's Hospital\",\n",
       "  \"St. Theresa's Hospital\",\n",
       "  'St. Francis Hospital (New York City)',\n",
       "  'Carolinas HealthCare System Pineville',\n",
       "  'Luton and Dunstable Hospital NHS Trust',\n",
       "  'Kaunas Clinics',\n",
       "  'Kaunas University of Medicine Hospital',\n",
       "  'Harbor Hospital',\n",
       "  'MedStar National Rehabilitation Hospital',\n",
       "  'Tacoma General Hospital',\n",
       "  'MultiCare',\n",
       "  \"Mary Bridge Children's Hospital\",\n",
       "  'PeaceHealth Sacred Heart Medical Center University District',\n",
       "  'PeaceHealth Sacred Heart Medical Center at RiverBend',\n",
       "  'USC University Hospital',\n",
       "  'Hackensack University Medical Center North at Pascack Valley',\n",
       "  'Riverside osteopathic hospital',\n",
       "  'Medical Center Of The Galilee',\n",
       "  'Saint Thomas - West Hospital',\n",
       "  'Saint Thomas - Rutherford Hospital',\n",
       "  'Einstein Medical Center',\n",
       "  'Saint Thomas - Midtown Hospital (Nashville)',\n",
       "  'Wills Eye Hospital',\n",
       "  'Mount Sinai Medical Center',\n",
       "  '551st United States Air Force Hospital',\n",
       "  'University of Maryland Rehabilitation & Orthopaedic Institute',\n",
       "  \"Dayton Children's Hospital\",\n",
       "  'Juan S. Alano Memorial Hospital',\n",
       "  'Montefiore New Rochelle Hospital',\n",
       "  'Fort Saskatchewan Community Hospital',\n",
       "  'University of Maryland Charles Regional Medical Center',\n",
       "  'McLaren Flint',\n",
       "  'Providence Care',\n",
       "  'The Madras Medical Mission',\n",
       "  'Naval Hospital Boston',\n",
       "  'Tillamook Regional Medical Center',\n",
       "  'Bolton NHS Foundation Trust',\n",
       "  'Karmanos Cancer Institute',\n",
       "  'Calvary Hospital (Bronx)',\n",
       "  \"St. Luke's University Health Network\",\n",
       "  'Carroll Hospital',\n",
       "  'Ohio State University Wexner Medical Center',\n",
       "  'Southend University Hospital NHS Foundation Trust',\n",
       "  \"Children's Medical Center Plano\",\n",
       "  'Overlook Hospital',\n",
       "  'Kettering General Hospital Foundation Trust',\n",
       "  'Springfield University Hospital',\n",
       "  'Rogue Valley Medical Center',\n",
       "  'P. D. Hinduja National Hospital and Medical Research Centre',\n",
       "  'Montgomery General Hospital',\n",
       "  'Yeovil District Hospital NHS Foundation Trust',\n",
       "  \"Lady Cilento Children's Hospital\",\n",
       "  'Naggalama Hospital',\n",
       "  'JFK Medical Center (Edison, New Jersey)',\n",
       "  'District Headquarters Hospital Battagram',\n",
       "  'NYC Health + Hospitals/Coler',\n",
       "  'Harrogate and District NHS Foundation Trust',\n",
       "  \"Shushrusha Citizens' Co-operative Hospital\",\n",
       "  'University Hospital Limerick',\n",
       "  'Hoag Memorial Hospital Presbyterian',\n",
       "  'Helen & Douglas House',\n",
       "  'Gouverneur Health',\n",
       "  'Gouverneur Healthcare Services',\n",
       "  'Nemours Alfred I. duPont Hospital for Children',\n",
       "  'University Hospital Waterford',\n",
       "  'Our Lady of Lourdes Hospital, Drogheda',\n",
       "  'University College Hospital at Westmoreland Street',\n",
       "  'Integris Bass Baptist Health Center',\n",
       "  'China-Japan Friendship Hospital',\n",
       "  'Good Samaritan Hospital (Baltimore)',\n",
       "  'University of Illinois Hospital & Health Sciences System',\n",
       "  'County Hospital, Stafford',\n",
       "  'St. Elizabeth Hospital (Enumclaw, Washington)',\n",
       "  'Sultan Haji Ahmad Shah Hospital',\n",
       "  'Mount Elizabeth Novena Hospital',\n",
       "  'St John of God Hospital, Subiaco',\n",
       "  'Augusta University Medical Center',\n",
       "  'MCGHealth',\n",
       "  'Georgia Regents Medical Center',\n",
       "  'Adventist HealthCare Washington Adventist Hospital',\n",
       "  'Netcare Milpark Hospital',\n",
       "  'City hospital No. 40',\n",
       "  'Mease Dunedin Hosptial',\n",
       "  'Bethesda Regional Health Centre',\n",
       "  'Bethesda Hospital (Steinbach)',\n",
       "  'York Teaching Hospital NHS Foundation Trust',\n",
       "  'Mercy Medical Center (Springfield)',\n",
       "  'Novant Health Charlotte Orthopedic Hospital',\n",
       "  'Dong-a University Hospital',\n",
       "  'Abrazo Maryvale Campus',\n",
       "  'Abrazo Central Campus',\n",
       "  'South Tyneside NHS Foundation Trust',\n",
       "  'Novant Health Franklin Medical Center',\n",
       "  'Chavakacheri Hospital',\n",
       "  'Henry Medical Center',\n",
       "  'Queen of the Valley Medical Center',\n",
       "  'Lausanne University Hospital',\n",
       "  'Seventh-day Adventist Hospital',\n",
       "  'Boulder Community Health',\n",
       "  'The Tunbridge Wells Hospital',\n",
       "  'Hospital Damas',\n",
       "  'College Medical Center',\n",
       "  'Good Samaritan Medical Center (West Palm Beach)',\n",
       "  \"Ford's Hospital\",\n",
       "  'PIH Health Hospital - Downey',\n",
       "  'Indian Hospital',\n",
       "  'Good Samaritan Hospital Medical Center (West Islip)',\n",
       "  \"King Edward VII's Hospital\",\n",
       "  \"St Bartholomew's Hospital, Rochester\",\n",
       "  'Presbyterian Hospital, Durtlang',\n",
       "  'Deaconess Hospital (Spokane, Washington)',\n",
       "  'Integris Southwest Medical Center',\n",
       "  'Tamil Nadu Government Multi Super Speciality Hospital',\n",
       "  'Tamilnadu Government Multi Super Speciality Hospital',\n",
       "  'University Hospital Kerry',\n",
       "  'EMMS Nazareth Hospital',\n",
       "  'St Francis Chronic Hospital',\n",
       "  'UPMC Altoona']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "max_length = 10\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def get_semantic_features(target_name, source_name, target_values, source_value):\n",
    "    \"\"\"\n",
    "    Compute semantic similarity features between a single source_value and a list of target_values.\n",
    "    Returns [max_similarity, min_similarity, avg_similarity]\n",
    "    \"\"\"\n",
    "    if len(target_values) == 0:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "    source_embedding = model.encode([str(source_value)])\n",
    "    target_embeddings = model.encode([str(x) for x in target_values])\n",
    "\n",
    "    similarities = cosine_similarity(source_embedding, target_embeddings)\n",
    "    max_similarity = similarities.max()\n",
    "    min_similarity = similarities.min()\n",
    "    avg_similarity = similarities.mean()\n",
    "\n",
    "    return [max_similarity, min_similarity, avg_similarity]\n",
    "\n",
    "\n",
    "def get_lexical_features(target_name, source_name, target_values, source_value):\n",
    "    \"\"\"\n",
    "    Compute Levenshtein similarity features between a single source_value and a list of target_values.\n",
    "    Returns [max_sim, min_sim, avg_sim]\n",
    "    \"\"\"\n",
    "    if len(target_values) == 0:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "    similarities = [\n",
    "        Levenshtein.normalized_similarity(source_value, target)\n",
    "        for target in target_values\n",
    "    ]\n",
    "    max_sim = max(similarities)\n",
    "    min_sim = min(similarities)\n",
    "    avg_sim = sum(similarities) / len(similarities)\n",
    "\n",
    "    return [max_sim, min_sim, avg_sim]\n",
    "\n",
    "\n",
    "def get_statistic_features(target_name, source_name, target_values, source_value):\n",
    "    \"\"\"\n",
    "    Compute simple ratio-based statistic features using a single source_value.\n",
    "    Returns [ratio]\n",
    "    \"\"\"\n",
    "    if len(target_values) == 0:\n",
    "        return [0.0]\n",
    "\n",
    "    # With a single source_value, ratio is either 1/len(target_values)\n",
    "    return [1.0 / len(target_values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "@dataclass\n",
    "class DateDetectResult:\n",
    "    parsed: pd.Series\n",
    "    success_rate: float\n",
    "    dayfirst: bool\n",
    "    yearfirst: bool\n",
    "\n",
    "def _try_parse(col: pd.Series, *, dayfirst=False, yearfirst=False, to_date=False, utc=True) -> pd.Series:\n",
    "    dt = pd.to_datetime(\n",
    "        col, errors=\"coerce\", infer_datetime_format=True,\n",
    "        dayfirst=dayfirst, yearfirst=yearfirst, utc=utc\n",
    "    )\n",
    "    return dt.dt.normalize() if to_date else dt\n",
    "\n",
    "def _best_datetime_parse(col: pd.Series, to_date=False, utc=True) -> DateDetectResult:\n",
    "    # Try four common strategies; pick the one that parses the most values\n",
    "    strategies = [\n",
    "        (False, False),\n",
    "        (True,  False),\n",
    "        (False, True),\n",
    "        (True,  True),\n",
    "    ]\n",
    "    best = None\n",
    "    best_rate = -1.0\n",
    "    best_series = None\n",
    "    best_flags = (False, False)\n",
    "\n",
    "    for df, yf in strategies:\n",
    "        parsed = _try_parse(col, dayfirst=df, yearfirst=yf, to_date=to_date, utc=utc)\n",
    "        rate = parsed.notna().mean()\n",
    "        if rate > best_rate:\n",
    "            best_rate, best_series, best_flags = rate, parsed, (df, yf)\n",
    "\n",
    "    return DateDetectResult(parsed=best_series, success_rate=best_rate,\n",
    "                            dayfirst=best_flags[0], yearfirst=best_flags[1])\n",
    "\n",
    "def detect_and_normalize_datetime(col: pd.Series, *, min_success=0.55, to_date=False, utc=True) -> Tuple[bool, pd.Series]:\n",
    "    \"\"\"\n",
    "    Returns (is_datetime_like, parsed_series).\n",
    "    A column is treated as datetime-like if at least `min_success` of values parse.\n",
    "    \"\"\"\n",
    "    res = _best_datetime_parse(col, to_date=to_date, utc=utc)\n",
    "    return (res.success_rate >= min_success), res.parsed\n",
    "\n",
    "def datetime_row_match(\n",
    "    df: pd.DataFrame,\n",
    "    source_col: str,\n",
    "    target_col: str,\n",
    "    *,\n",
    "    date_only: bool = True,\n",
    "    tolerance: Optional[pd.Timedelta] = None,\n",
    "    min_success: float = 0.55,\n",
    "    require_both_datetime: bool = True,\n",
    "    utc: bool = True,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Auto-detect datetime columns, normalize, then row-wise match.\n",
    "\n",
    "    - date_only=True: match by calendar date (time ignored)\n",
    "    - tolerance=None: exact equality (NaT-safe)\n",
    "    - tolerance=Timedelta: match within +/- tolerance (requires datetimes, not date-only)\n",
    "    - require_both_datetime=True: if either column isn't datetime-like, return all False\n",
    "    \"\"\"\n",
    "    s_is_dt, s_parsed = detect_and_normalize_datetime(df[source_col], to_date=date_only, utc=utc, min_success=min_success)\n",
    "    t_is_dt, t_parsed = detect_and_normalize_datetime(df[target_col], to_date=date_only, utc=utc, min_success=min_success)\n",
    "\n",
    "    if require_both_datetime and not (s_is_dt and t_is_dt):\n",
    "        # columns don’t look like dates → no matches\n",
    "        return pd.Series(False, index=df.index)\n",
    "\n",
    "    # If one looks like datetime and the other doesn’t, still try (but many will be NaT)\n",
    "    if tolerance is None:\n",
    "        # exact equality at chosen granularity\n",
    "        return s_parsed.eq(t_parsed)\n",
    "    else:\n",
    "        # tolerance only makes sense when we kept time-of-day (date_only=False recommended)\n",
    "        valid = s_parsed.notna() & t_parsed.notna()\n",
    "        diff = (s_parsed - t_parsed).abs()\n",
    "        return valid & (diff <= tolerance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- New imports (top of file) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "# =========================\n",
    "# 1) Helper: datetime normalize (vectorized)\n",
    "# =========================\n",
    "def _normalize_datetime_series(series, *, to_date=True, utc=True):\n",
    "    \"\"\"\n",
    "    Vectorized parse to datetime. Returns datetime64[ns, UTC] if utc=True,\n",
    "    and normalizes to midnight if to_date=True (calendar-date equality).\n",
    "    \"\"\"\n",
    "    dt = pd.to_datetime(series, errors=\"coerce\", infer_datetime_format=True, utc=utc)\n",
    "    return dt.dt.normalize() if to_date else dt\n",
    "\n",
    "def _looks_like_datetime(series, min_success=0.55):\n",
    "    \"\"\"Heuristic: consider a series datetime-like if parse success rate >= min_success.\"\"\"\n",
    "    parsed = pd.to_datetime(series, errors=\"coerce\", infer_datetime_format=True, utc=True)\n",
    "    return parsed.notna().mean() >= min_success\n",
    "\n",
    "# =========================\n",
    "# 2) Algorithms\n",
    "# =========================\n",
    "\n",
    "def lexical_algorithm(source, targets):\n",
    "    source_column = 'source'\n",
    "    target_column = 'target'\n",
    "    source_dataset = pd.DataFrame({source_column: [source]})\n",
    "    target_dataset = pd.DataFrame({target_column: targets})\n",
    "    matches = bdi.match_values(\n",
    "        source_dataset,\n",
    "        target_dataset,\n",
    "        attribute_matches=(source_column, target_column),\n",
    "        method=\"edit_distance\",\n",
    "    )\n",
    "    return matches[\"target_value\"].iloc[0] if len(matches) else None\n",
    "\n",
    "def semantic_algorithm(source, targets):\n",
    "    source_column = 'source'\n",
    "    target_column = 'target'\n",
    "    source_dataset = pd.DataFrame({source_column: [source]})\n",
    "    target_dataset = pd.DataFrame({target_column: targets})\n",
    "    matches = bdi.match_values(\n",
    "        source_dataset,\n",
    "        target_dataset,\n",
    "        attribute_matches=(source_column, target_column),\n",
    "        method=\"embedding\",\n",
    "    )\n",
    "    return matches[\"target_value\"].iloc[0] if len(matches) else None\n",
    "\n",
    "def llm_reasoning_algorithm(source, targets):\n",
    "    source_column = 'source'\n",
    "    target_column = 'target'\n",
    "    source_dataset = pd.DataFrame({source_column: [source]})\n",
    "    target_dataset = pd.DataFrame({target_column: targets})\n",
    "    matches = bdi.match_values(\n",
    "        source_dataset,\n",
    "        target_dataset,\n",
    "        attribute_matches=(source_column, target_column),\n",
    "        method=\"llm\",\n",
    "    )\n",
    "    return matches[\"target_value\"].iloc[0] if len(matches) else None\n",
    "\n",
    "# --- Datetime matching (normalize both cols, then row-wise compare) ---\n",
    "def date_algorithm(source, targets, *, tolerance: timedelta | None = None, date_only: bool = True):\n",
    "    \"\"\"\n",
    "    Normalize both source and targets as datetimes and return the best target.\n",
    "    - If tolerance is None: exact equality (calendar date if date_only=True)\n",
    "    - If tolerance provided: choose the nearest within tolerance (time-of-day kept if date_only=False)\n",
    "    Returns the matched target value, or None if no match.\n",
    "    \"\"\"\n",
    "    # Build tiny dataframes so we can vectorize uniformly\n",
    "    s_df = pd.DataFrame({\"source\": [source]})\n",
    "    t_df = pd.DataFrame({\"target\": targets})\n",
    "\n",
    "    # Quick guard: if neither column parses reasonably, bail\n",
    "    if not (_looks_like_datetime(s_df[\"source\"]) or _looks_like_datetime(t_df[\"target\"])):\n",
    "        return None\n",
    "\n",
    "    # Normalize both\n",
    "    s_parsed = _normalize_datetime_series(s_df[\"source\"], to_date=date_only)\n",
    "    t_parsed = _normalize_datetime_series(t_df[\"target\"], to_date=date_only)\n",
    "\n",
    "    s_val = s_parsed.iloc[0]\n",
    "    if pd.isna(s_val):\n",
    "        return None\n",
    "\n",
    "    # Exact equality on chosen granularity\n",
    "    if tolerance is None:\n",
    "        mask = t_parsed.eq(s_val)\n",
    "        if not mask.any():\n",
    "            return None\n",
    "        # Return the first exact match’s original target string\n",
    "        idx = mask.idxmax()\n",
    "        return t_df[\"target\"].iloc[idx]\n",
    "\n",
    "    # Tolerance-based: find nearest within tolerance\n",
    "    valid = t_parsed.notna()\n",
    "    if not valid.any():\n",
    "        return None\n",
    "    diffs = (t_parsed[valid] - s_val).abs()\n",
    "    within = diffs <= pd.Timedelta(tolerance)\n",
    "    if not within.any():\n",
    "        return None\n",
    "    # pick nearest\n",
    "    best_idx = diffs[within].idxmin()\n",
    "    return t_df[\"target\"].loc[best_idx]\n",
    "\n",
    "# --- Simple regex matcher baseline ---\n",
    "def regex_algorithm(source, targets):\n",
    "    \"\"\"\n",
    "    Very light regex baseline:\n",
    "    - Extract alnum tokens from source and each target\n",
    "    - Score by size of token intersection (Jaccard-like)\n",
    "    - Return best-scoring target (ties → first)\n",
    "    \"\"\"\n",
    "    if not targets:\n",
    "        return None\n",
    "    tok = lambda s: set(re.findall(r\"[A-Za-z0-9]+\", str(s).lower()))\n",
    "    s_tokens = tok(source)\n",
    "    if not s_tokens:\n",
    "        return None\n",
    "\n",
    "    best_i, best_score = None, -1.0\n",
    "    for i, t in enumerate(targets):\n",
    "        t_tokens = tok(t)\n",
    "        if not t_tokens:\n",
    "            continue\n",
    "        inter = len(s_tokens & t_tokens)\n",
    "        union = len(s_tokens | t_tokens)\n",
    "        score = inter / union if union else 0.0\n",
    "        if score > best_score:\n",
    "            best_score, best_i = score, i\n",
    "\n",
    "    return targets[best_i] if best_i is not None else None\n",
    "\n",
    "# =========================\n",
    "# 3) Actions + primitives\n",
    "# =========================\n",
    "actions_dict = {\n",
    "    0: 'lexical',\n",
    "    1: 'semantic',\n",
    "    2: 'llm',\n",
    "    3: 'date',     # NEW\n",
    "    4: 'regex',    # NEW\n",
    "}\n",
    "primitives_dict = {\n",
    "    'lexical': lexical_algorithm,\n",
    "    'semantic': semantic_algorithm,\n",
    "    'llm': llm_reasoning_algorithm,\n",
    "    'date': date_algorithm,\n",
    "    'regex': regex_algorithm,\n",
    "}\n",
    "num_algorithms = len(actions_dict)\n",
    "\n",
    "\n",
    "\n",
    "class ValueMatchingEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, dataset, max_steps=3):\n",
    "        super(ValueMatchingEnv, self).__init__()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.max_steps = max_steps\n",
    "        self.action_space = gym.spaces.Discrete(num_algorithms)\n",
    "\n",
    "        feature_dim = 7 + max_steps\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0, high=1.0,\n",
    "            shape=(feature_dim,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Episode-specific values\n",
    "        self.source = None\n",
    "        self.targets = None\n",
    "        self.gold = None\n",
    "\n",
    "        self.steps_taken = 0\n",
    "        self.action_history = None\n",
    "\n",
    "    # ---- Convert action history to normalized vector ----\n",
    "    def _encode_history(self):\n",
    "        encoded = []\n",
    "        for action in self.action_history:\n",
    "            if action == -1:\n",
    "                encoded.append(0.0)  # unused slot\n",
    "            else:\n",
    "                encoded.append((action + 1) / num_algorithms)\n",
    "        return encoded\n",
    "\n",
    "    # ---- Compute full feature vector ----\n",
    "    def _compute_features(self, source, targets):\n",
    "        lexical_features = get_lexical_features('target', 'source', targets, source)\n",
    "        semantic_features = get_semantic_features('target', 'source', targets, source)\n",
    "        statistic_features = get_statistic_features('target', 'source', targets, source)\n",
    "\n",
    "        history_vector = self._encode_history()\n",
    "\n",
    "        all_features = lexical_features + semantic_features + statistic_features + history_vector\n",
    "        return np.array(all_features, dtype=np.float32)\n",
    "\n",
    "    # ---- Reset episode ----\n",
    "    def reset(self):\n",
    "    # randomly pick an item from dataset\n",
    "        sample = random.choice(self.dataset)\n",
    "        self.source = sample['source']\n",
    "        self.targets = sample['targets']\n",
    "        self.gold = sample['gold']\n",
    "\n",
    "        self.steps_taken = 0\n",
    "        self.action_history = [-1] * self.max_steps\n",
    "\n",
    "        self.state = self._compute_features(self.source, self.targets)\n",
    "        return self.state\n",
    "\n",
    "\n",
    "    # ---- Step ----\n",
    "    # ---- Step ----\n",
    "    def step(self, action):\n",
    "    # Record algorithm in history\n",
    "        if self.steps_taken < self.max_steps:\n",
    "            self.action_history[self.steps_taken] = action\n",
    "        self.steps_taken += 1\n",
    "\n",
    "        alg_name = actions_dict[action]\n",
    "\n",
    "        try:\n",
    "            if alg_name == 'date':\n",
    "                # You can pick the policy you prefer:\n",
    "                # exact calendar date:\n",
    "                predicted = primitives_dict[alg_name](self.source, self.targets, tolerance=None, date_only=True)\n",
    "                # or within 1 day keeping time: predicted = primitives_dict[alg_name](self.source, self.targets, tolerance=timedelta(days=1), date_only=False)\n",
    "            else:\n",
    "                predicted = primitives_dict[alg_name](self.source, self.targets)\n",
    "        except Exception:\n",
    "            predicted = None  # fail-safe, let policy try next action\n",
    "\n",
    "        reward = 1.0 if (predicted is not None and predicted == self.gold) else 0.0\n",
    "        done = (reward == 1.0) or (self.steps_taken >= self.max_steps)\n",
    "\n",
    "        if not done:\n",
    "            self.state = self._compute_features(self.source, self.targets)\n",
    "        else:\n",
    "            self.state = np.zeros(self.observation_space.shape, dtype=np.float32)\n",
    "\n",
    "        info = {\n",
    "            \"predicted\": predicted,\n",
    "            \"gold\": self.gold,\n",
    "            \"algorithm\": alg_name,\n",
    "            \"history\": self.action_history.copy()\n",
    "        }\n",
    "        return self.state, reward, done, info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Total Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 40701698-1f1f-4c3f-85bf-06c7245dfd3a)')' thrown while requesting HEAD https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2, Total Reward: 1.0\n",
      "Episode 3, Total Reward: 1.0\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/llms/openai/openai.py:745\u001b[39m, in \u001b[36mOpenAIChatCompletion.completion\u001b[39m\u001b[34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[39m\n\u001b[32m    744\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/llms/openai/openai.py:647\u001b[39m, in \u001b[36mOpenAIChatCompletion.completion\u001b[39m\u001b[34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[39m\n\u001b[32m    644\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    645\u001b[39m         status_code=\u001b[32m422\u001b[39m, message=\u001b[33m\"\u001b[39m\u001b[33mmax retries must be an int\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m openai_client: OpenAI = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_openai_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_async\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/llms/openai/openai.py:395\u001b[39m, in \u001b[36mOpenAIChatCompletion._get_openai_client\u001b[39m\u001b[34m(self, is_async, api_key, api_base, api_version, timeout, max_retries, organization, client, shared_session)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     _new_client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOpenAIChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_sync_http_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m## SAVE CACHE KEY\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/main.py:2164\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   2158\u001b[39m     logging.post_call(\n\u001b[32m   2159\u001b[39m         \u001b[38;5;28minput\u001b[39m=messages,\n\u001b[32m   2160\u001b[39m         api_key=api_key,\n\u001b[32m   2161\u001b[39m         original_response=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m   2162\u001b[39m         additional_args={\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: headers},\n\u001b[32m   2163\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optional_params.get(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2167\u001b[39m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/main.py:2136\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   2135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2136\u001b[39m         response = \u001b[43mopenai_chat_completions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2137\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2138\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2139\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2140\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2141\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2142\u001b[39m \u001b[43m            \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2143\u001b[39m \u001b[43m            \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2144\u001b[39m \u001b[43m            \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2145\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2146\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2147\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2148\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2149\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2151\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[32m   2152\u001b[39m \u001b[43m            \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2153\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2154\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshared_session\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshared_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2155\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2157\u001b[39m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/llms/openai/openai.py:756\u001b[39m, in \u001b[36mOpenAIChatCompletion.completion\u001b[39m\u001b[34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[39m\n\u001b[32m    755\u001b[39m     error_headers = \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    757\u001b[39m     status_code=status_code,\n\u001b[32m    758\u001b[39m     message=error_text,\n\u001b[32m    759\u001b[39m     headers=error_headers,\n\u001b[32m    760\u001b[39m     body=error_body,\n\u001b[32m    761\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m     action = \u001b[38;5;28mmax\u001b[39m(q_values, key=q_values.get)  \u001b[38;5;66;03m# Exploit\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Take action\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m next_state, reward, done, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m total_reward += reward\n\u001b[32m     38\u001b[39m next_state_key = state_to_key(next_state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mValueMatchingEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m.steps_taken += \u001b[32m1\u001b[39m\n\u001b[32m    129\u001b[39m alg_name = actions_dict[action]\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m predicted = \u001b[43mprimitives_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43malg_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m reward = \u001b[32m1.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predicted == \u001b[38;5;28mself\u001b[39m.gold \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n\u001b[32m    133\u001b[39m done = reward == \u001b[32m1.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_taken >= \u001b[38;5;28mself\u001b[39m.max_steps\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mllm_reasoning_algorithm\u001b[39m\u001b[34m(source, targets)\u001b[39m\n\u001b[32m     43\u001b[39m source_dataset = pd.DataFrame({source_column: [source] })\n\u001b[32m     44\u001b[39m target_dataset = pd.DataFrame({ target_column: targets })\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m matches = \u001b[43mbdi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatch_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m                        \u001b[49m\u001b[43msource_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mattribute_matches\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m matches[\u001b[33m\"\u001b[39m\u001b[33mtarget_value\u001b[39m\u001b[33m\"\u001b[39m].iloc[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/bdikit/api.py:323\u001b[39m, in \u001b[36mmatch_values\u001b[39m\u001b[34m(source, target, attribute_matches, method, source_context, target_context, method_args, standard_args, output_format, use_cache)\u001b[39m\n\u001b[32m    316\u001b[39m target_ctx = _create_context(\n\u001b[32m    317\u001b[39m     target_dataset,\n\u001b[32m    318\u001b[39m     target_attribute,\n\u001b[32m    319\u001b[39m     user_context=target_context,\n\u001b[32m    320\u001b[39m )\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     matches = \u001b[43m_cache_value_matches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmatch_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatcher_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatch_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmatcher_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatcher_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    332\u001b[39m     matches = matcher_instance.match_values(\n\u001b[32m    333\u001b[39m         source_values, target_values, source_ctx, target_ctx\n\u001b[32m    334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/bdikit/api.py:560\u001b[39m, in \u001b[36m_cache_value_matches\u001b[39m\u001b[34m(source_values, target_values, source_ctx, target_ctx, match_func, matcher_obj, **match_kwargs)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cached_result\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m result = \u001b[43mmatch_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmatch_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m save_in_cache(result, hash_id)\n\u001b[32m    569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/bdikit/value_matching/llm.py:45\u001b[39m, in \u001b[36mLLM.match_values\u001b[39m\u001b[34m(self, source_values, target_values, source_context, target_context)\u001b[39m\n\u001b[32m     42\u001b[39m matches = []\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source_value \u001b[38;5;129;01min\u001b[39;00m source_values:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     response = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are an intelligent system that given a term, you have to choose a value from a list that best matches the term.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFor the term: \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msource_value\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, choose a value from this list \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_values\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     55\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReturn the value from the list with a similarity score, between 0 and 1, with 1 indicating the highest similarity. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     56\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43madditional_context\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     57\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDO NOT PROVIDE ANY OTHER OUTPUT TEXT OR EXPLANATION. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     58\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mOnly provide a Python dictionary. For example \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mterm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mterm from the list\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: 0.8}.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     response_message = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/utils.py:1382\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1379\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1380\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1381\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/utils.py:1251\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1249\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1250\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1254\u001b[39m     kwargs=kwargs,\n\u001b[32m   1255\u001b[39m     call_type=call_type,\n\u001b[32m   1256\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/main.py:3842\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   3839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3840\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3841\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3842\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3845\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2328\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2327\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/nlp312/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:449\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    445\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    447\u001b[39m ):\n\u001b[32m    448\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\n\u001b[32m    450\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthenticationError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    451\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    452\u001b[39m         model=model,\n\u001b[32m    453\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    454\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    455\u001b[39m     )\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMistral API raised a streaming error\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str:\n\u001b[32m    457\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mAuthenticationError\u001b[39m: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Create environment\n",
    "env = ValueMatchingEnv(dataset, max_steps=3)\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "# Initialize Q-table\n",
    "Q = {}\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 0.1    # learning rate\n",
    "gamma = 0.9    # discount factor\n",
    "epsilon = 0.5  # exploration rate\n",
    "\n",
    "# Helper function to convert numeric state vector to tuple (hashable for Q-table)\n",
    "def state_to_key(state):\n",
    "    return tuple(state.round(3))  # round to reduce floating-point noise\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 1000\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        state_key = state_to_key(state)\n",
    "        \n",
    "        # Choose action\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            q_values = {a: Q.get((state_key, a), 0) for a in range(num_actions)}\n",
    "            action = max(q_values, key=q_values.get)  # Exploit\n",
    "        \n",
    "        # Take action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        next_state_key = state_to_key(next_state)\n",
    "        next_q_values = {a: Q.get((next_state_key, a), 0) for a in range(num_actions)}\n",
    "        max_next_q_value = max(next_q_values.values()) if next_q_values else 0\n",
    "        \n",
    "        # Update Q-table\n",
    "        current_q_value = Q.get((state_key, action), 0)\n",
    "        updated_q_value = current_q_value + alpha * (reward + gamma * max_next_q_value - current_q_value)\n",
    "        Q[(state_key, action)] = updated_q_value\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "# --- Evaluate trained agent ---\n",
    "total_rewards = []\n",
    "num_eval_episodes = 3\n",
    "\n",
    "for _ in range(num_eval_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        state_key = state_to_key(state)\n",
    "        q_values = {a: Q.get((state_key, a), 0) for a in range(num_actions)}\n",
    "        action = max(q_values, key=q_values.get)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "    \n",
    "    print('Predicted target:', info['predicted_target'])\n",
    "    print('Gold target:', info['gold'])\n",
    "    print('Algorithm used:', info['algorithm_used'])\n",
    "    print('Test reward:', total_reward)\n",
    "    total_rewards.append(total_reward)\n",
    "\n",
    "print(f\"Average Total Reward: {np.mean(total_rewards)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
